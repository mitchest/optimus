#' @title Find an optimal classification among competing clustering solutions
#'
#' @description \code{find_optimal} takes a clustering solution, or a set of related clustering solutions, and calculates the sum-of-AIC value for the solution/s. The smallest sum-of-AIC value is the optimal solution.
#'
#' @param data a data frame (or object that can be coerced by \code{\link[base]{as.data.frame}} containing the "raw" multivariate data. This is not necessarily the data used by the clustering algorithm - it is the data on which you are testing the predictive ablity of the clustering solutions.
#' @param clustering either an object on which \code{\link[stats]{cutree}} will work, or a list with one or more components, each containing a vector of cluster labels. The number of cluster labels (either generated by \code{\link[stats]{cutree}} or supplied in each list component) must match the number of rows of the object supplied in the \code{data} argument.
#' @param family a character string denoting the error distribution to be used for model fitting. The options are similar to those in \code{\link[stats]{family}}, but are more limited - see Details.
#' @param cutree logical. Whether \code{\link[stats]{cutree}} can be used on the object supplied to the \code{clustering} argument
#' @param cutreeLevels a numerical vector specifying the different paritioning levels to calculate sum-of-AIC for (that is the values of \code{k} to be supplied to \code{\link[stats]{cutree}}). Ignored if \code{cutree = FALSE}, as the number of partitions will be automatically generated from the number of unique levels in each component of \code{clustering}
#' @param K number of trials in binomial regression. By default, K=1 for presence-absence data (logistic regression).
#'
#' @details \code{find_optimal} is built on the premise that a \emph{good} clustering solution (i.e. a classification) should provide information about the composition and abundance of the multivariate data it is classifying. A natural way to formalize this is with a predictive model, where group membership (clusters) is the predictor, and the multivariate data (site by variables matrix) is the response. \code{find_optimal} fits linear models to each variable, and calculates the sum of the AIC value (sum-of-AIC) for each model. sum-of-AIC is motivated as an estimate of Kullback-Leibler distance, so we posit that the clustering solution that minimises the sum-of-AIC value is the \emph{best}. So, in context of optimal partitioning, \code{find_optimal} can be used to automatically and objectively decide which clustering solution is the best among competing solutions. Lyons et al. (2016) provides background, a detailed description of the methodology, and application of sum-of-AIC on both real and simulated ecological multivariate abundance data.
#'
#' At present, \code{find_optimal} supports the following error distributions for model fitting:
#' \itemize{
#'   \item Gaussian (LM)
#'   \item Negative Binomial (GLM with log link)
#'   \item Poisson (GLM with log link)
#'   \item Binomial (GLM with logit link)
#'   \item Ordinal (Proportional odds model with logit link)
#' }
#'
#' Gaussian LMs should be used for 'normal' data. Negative Binomial and Poisson GLMs shold be used for count data. Binomial GLMs should be used for binary and presence/absence data (when \code{K=1}), or trials data (e.g. frequency scores). If Binomial regression is being used with \code{K>1}, then \code{data} should be numerical values between 0 and 1, interpreted as the proportion of successful cases, where the total number of cases is given by \code{K} (see Details in \code{\link[stats]{family}}). Ordinal regression should be used for ordinal data, for example, cover-abundance scores. LMs fit via \code{\link[mvabund]{manylm}}; GLMs fit via \code{\link[mvabund]{manyglm}}; proportional odds model fit via \code{\link[ordinal]{clm}}.
#'
#' @return a data frame containing the sum-of-AIC value for each clustering solution, along with the number of clusters the solution had. The object is of class \code{aicsums}
#'
#' Attributes for the data frame are:
#'
#' \describe{
##'   \item{\code{attr}}{...}
##'   \item{\code{attr}}{...}
##'   \item{\code{attr}}{...}
##'   \item{\code{attr}}{...}
##' }
#'
#' @author Mitchell Lyons
#'
#' @references Lyons et al. 2016. Model-based assessment of ecological community classifications. \emph{Journal of Vegetation Science}, \strong{27 (4)}: 704--715.
#'
#' @seealso S3 plotting function, S3 residual plotting function for the optimal solution, a characteristic species function for the optimal solution
#'
#' @keywords optimal
#'
#' @examples
#'
#' ## Example using 1) an object that cutree works on, and 2) supplying a list of clustering solutions, from kmeans
#'
#' @export


find_optimal <- function(data, clustering, family, cutree = TRUE, cutreeLevels = 2:10, K=1) {
  # test multivar data input (i.e. is char/num/factor)

  # test clustering is a cutree onject or a list, and if it's a list, make sure all elements are vectors with the same length

  # test data has same number rows as clustering solutions

  # inform that clustering solutions will be coerced to

  # test specified family is supported
  supported_fams <- c("gaussian", "negative.binomial", "poisson", "binomial", "ordinal")
  if (!family %in% supported_fams) {
    stop(paste0("Family specified is not valid (typo?) or not yet supported, please choose from: ",
         paste(supported_fams, collapse = ", ")))
  }

  # test cutreeLevels is a vector

  # make list of clustering solutions from cutree-able object
  cutree_to_list <- function(x, clustering) {cutree(tree = clustering, k = x)}
  cluster_list <- lapply(X = as.list(cutreeLevels), FUN = cutree_to_list, clustering = clustering)

  # if a list was supplied, cutreeLevels will be generated automatically from the number of unique levels in each component (via unique())

  # fit models to calculate sum-of-aic
  if (family == "gaussian") {
    aic_sums <- data.frame(sum_aic = gaussian_loop(cluster_list, data, cutreeLevels),
                           nclusters = cutreeLevels)
  }

  if (family == "negative.binomial") {
    aic_sums <- data.frame(sum_aic = negbin_loop(cluster_list, data),
                           nclusters = cutreeLevels)
  }

  if (family == "poisson") {
    aic_sums <- data.frame(sum_aic = poisson_loop(cluster_list, data),
                           nclusters = cutreeLevels)
  }

  if (family == "binomial") {
    aic_sums <- data.frame(sum_aic = binomial_loop(cluster_list, data, K=K),
                           nclusters = cutreeLevels)
  }

  if (family == "ordinal") {
    aic_sums <- data.frame(sum_aic = ordinal_loop(cluster_list, data),
                           nclusters = cutreeLevels)
  }

  # attributes/class for aic_sums
  class(aic_sums) <- c("aicsums","data.frame")

  # return data frame ready for plotting
  aic_sums
}

