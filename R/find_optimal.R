#' @title Find an optimal classification among competing clustering solutions
#'
#' @description \code{find_optimal} takes a clustering solution, or a set of related clustering solutions, fits models based on the underlying multivariate data, and calculates the sum-of-AIC value for the solution/s. The smallest sum-of-AIC value is the optimal solution.
#'
#' @param data a data frame (or object that can be coerced by \code{\link[base]{as.data.frame}} containing the "raw" multivariate data. This is not necessarily the data used by the clustering algorithm - it is the data on which you are testing the predictive ablity of the clustering solutions.
#' @param clustering either an object on which \code{\link[stats]{cutree}} will work, or a list with one or more components, each containing an atomic vector of cluster labels (that can be coerced by \code{\link[base]{as.factor}}). The number of cluster labels (either generated by \code{\link[stats]{cutree}} or supplied in each list component) must match the number of rows of the object supplied in the \code{data} argument.
#' @param family a character string denoting the error distribution to be used for model fitting. The options are similar to those in \code{\link[stats]{family}}, but are more limited - see Details.
#' @param K number of trials in binomial regression. By default, K=1 for presence-absence data (with cloglog link).
#' @param cutree logical, but default is \code{NULL} for auto-detection. Whether \code{\link[stats]{cutree}} should be used on the object supplied to the \code{clustering} argument
#' @param cutreeLevels a numerical vector specifying the different paritioning levels to calculate sum-of-AIC for (that is the values of \code{k} to be supplied to \code{\link[stats]{cutree}}). Ignored if \code{cutree = FALSE}, as the number of partitions will be automatically generated from the number of unique levels in each component of \code{clustering}.
#' @param cutreeOveride logical. Ignored if \code{cutree = FALSE}. Should the checks on whether the object supplied to the \code{clustering} works with \code{\link[stats]{cutree}}? WARNING: only set \code{cutreeOveride = TRUE} if you are totally sure \code{\link[stats]{cutree}} works, but the error message is telling you it doesn't. See Arguments in \code{\link[stats]{cutree}} and first consider modifying the object supplied to clustering=.
#'
#' @details \code{find_optimal} is built on the premise that a \emph{good} clustering solution (i.e. a classification) should provide information about the composition and abundance of the multivariate data it is classifying. A natural way to formalize this is with a predictive model, where group membership (clusters) is the predictor, and the multivariate data (site by variables matrix) is the response. \code{find_optimal} fits linear models to each variable, and calculates the sum of the AIC value (sum-of-AIC) for each model. sum-of-AIC is motivated as an estimate of Kullback-Leibler distance, so we posit that the clustering solution that minimises the sum-of-AIC value is the \emph{best}. So, in context of optimal partitioning, \code{find_optimal} can be used to automatically and objectively decide which clustering solution is the best among competing solutions. Lyons et al. (2016) provides background, a detailed description of the methodology, and application of sum-of-AIC on both real and simulated ecological multivariate abundance data.
#'
#' At present, \code{find_optimal} supports the following error distributions for model fitting:
#' \itemize{
#'   \item Gaussian (LM)
#'   \item Negative Binomial (GLM with log link)
#'   \item Poisson (GLM with log link)
#'   \item Binomial (GLM with cloglog link for binary daya, logit link otherwise)
#'   \item Ordinal (Proportional odds model with logit link)
#' }
#'
#' Gaussian LMs should be used for 'normal' data. Negative Binomial and Poisson GLMs shold be used for count data. Binomial GLMs should be used for binary and presence/absence data (when \code{K=1}), or trials data (e.g. frequency scores). If Binomial regression is being used with \code{K>1}, then \code{data} should be numerical values between 0 and 1, interpreted as the proportion of successful cases, where the total number of cases is given by \code{K} (see Details in \code{\link[stats]{family}}). Ordinal regression should be used for ordinal data, for example, cover-abundance scores. For ordinal regression, data should be supplied as either 1) factors, with the appropriate ordinal level order specified (see \code{\link[base]{levels}}) or 2) numeric, which will be coerced into a factor with levels ordered in numerical order (e.g. cover-abundance/numeric response scores). LMs fit via \code{\link[mvabund]{manylm}}; GLMs fit via \code{\link[mvabund]{manyglm}}; proportional odds model fit via \code{\link[ordinal]{clm}}.
#'
#' @return a data frame containing the sum-of-AIC value for each clustering solution, along with the number of clusters the solution had. The object is of class \code{aicsums}.
#'
#' Attributes for the data frame are:
#'
#' \describe{
#'   \item{\code{family}}{ which error distribution was used for modelling, see Arguments}
#'   \item{\code{K}}{ number of cases for Binomial regression, see Arguments}
#'   \item{\code{cutree}}{ whether \code{\link[stats]{cutree}} was used, see Arguments}
#'   \item{\code{cutreeLevels}}{ number of paritioning levels specified, see Arguments}
#' }
#'
#' @author Mitchell Lyons
#'
#' @references Lyons et al. 2016. Model-based assessment of ecological community classifications. \emph{Journal of Vegetation Science}, \strong{27 (4)}: 704--715.
#'
#' @seealso \code{\link[optimus]{plot.aicsums}}, \code{\link[optimus]{get_characteristic}}, \code{\link[optimus]{merge_clusters}}, S3 for residual plots (at some stage)
#'
#' @keywords optimal, partition, partitioning
#'
#' @examples
#'
#' ## Prep the 'swamps' data
#' ## ======================
#'
#' data(swamps) # see ?swamps
#' swamps <- swamps[,-1]
#'
#' ## Assess clustering solutions using cutree() method
#' ## =================================================
#'
#' ## perhaps not the best clustering option, but this is base R
#' swamps_hclust <- hclust(d = dist(x = log1p(swamps), method = "canberra"),
#'                        method = "complete")
#'
#' ## calculate sum-of-AIC values for 2:40 clusters, using the hclust() output
#' swamps_hclust_aics <- find_optimal(data = swamps, clustering = swamps_hclust,
#' family = "poisson", cutreeLevels = 2:40)
#'
#' ## Note here that the data passed to find_optimal() was actually NOT the
#' ## data used for clustering (transform/distance), rather it was the
#' ## original abundance (response) data of interest
#'
#' ## plot - lower sum-of-AIC valuea indicate 'better' clustering
#' plot(swamps_hclust_aics)
#'
#'
#' \dontrun{
#' ## Assess clustering solutions by supplying a list of solutions
#' ## ============================================================
#'
#' ## again, we probably wouldn't do this, but for illustrative purposes
#' ## note that we are generating a list of solutions this time
#' swamps_kmeans <- lapply(X = 2:40,
#' FUN = function(x, data) {stats::kmeans(x = data, centers = x)$cluster},
#' data = swamps)
#'
#' ## calculate sum-of-AIC values for the list of clustering solutions
#' swamps_kmeans_aics <- find_optimal(data = swamps, clustering = swamps_kmeans,
#' family = "poisson") # note cutreeLevels= argument is not needed
#'
#' plot(swamps_kmeans_aics)
#' }
#'
#' ## See vignette for more explanation than this example
#' ## ============================================================
#'
#' @export


find_optimal <- function(data, clustering, family, K = 1, cutree = NULL, cutreeLevels = 2:10, cutreeOveride = FALSE) {
  data <- as.data.frame(data)

  # test specified family is supported
  supported_fams <- c("gaussian", "negative.binomial", "poisson", "binomial", "ordinal")
  if (!family %in% supported_fams) {
    stop("family specified is not valid (typo?) or not yet supported, please choose from: ",
                paste(supported_fams, collapse = ", "))
  }

  # test multivar data input (i.e. is char/num/factor)
  if (family != "ordinal" & any(unlist(lapply(data, class)) %in% c("factor", "character"))) {
    stop("some of the input data are factors or characters, are you looking for ordinal regression?")
  }

  if (family == "ordinal") {
    if (all(unlist(lapply(data, is.factor)))) {
      message("All data are factors, ordinal regression will use factor levels as is - ensure they are correct")
    }
    if (!all(unlist(lapply(data, is.factor))) & any(unlist(lapply(data, is.factor)))) {
      stop("Some data are factors, some are not - don't know how to proceed with ordinal regression")
    }
    if (all(unlist(lapply(data, is.numeric)))) {
      message("All data are numeric - will coerce to factor and levels will be in numeric order")
    }
  }

  # auto-detect whether cutree() can be used
  if (is.null(cutree) & !cutreeOveride) {
    if (all(c("merge","height") %in% names(clustering))){
      cutree <- TRUE
      message("clustering= object WILL work with cutree(), setting cutree=TRUE")
    } else {
      cutree <- FALSE
      message("clustering= object WILL NOT work with cutree(), setting cutree=FALSE")
    }
  }

  # test clustering is a cutree onject or a list, and if it's a list, make sure all elements are vectors with the same length, and check against number of samples in data
  if (cutree & !cutreeOveride) {
    if (!all(c("merge","height") %in% names(clustering))) { stop("cutree() will not work on the object supplied to the clustering= argument, maybe you want cutree=F? Also see Arguments in ?find_optimal") }
    if (!length(cutree(tree = clustering, k = 2)) == nrow(data)) { stop("Number of samples implied from calling cutree() on object supplied to clustering= does not match the number of rows of object supplied to data=. See Arguments in ?find_optimal") }
    if (!is.integer(cutreeLevels)) { stop("Object supplied to cutreeLevels= is not an integer") }
  }

  if (cutree & cutreeOveride) {
    warning("checks on whether object supplied to clustering= works with cutree() are being skipped")
    if (!length(cutree(tree = clustering, k = 2)) == nrow(data)) { stop("Number of samples implied from calling cutree() on object supplied to clustering= does not match the number of rows of object supplied to data=. See Arguments in ?find_optimal") }
    if (!is.integer(cutreeLevels)) { stop("Object supplied to cutreeLevels= is not an integer") }
  }

  if (!cutree) {
    message("Note: Using individual clustering solutions supplied to clustering=,")
    if (!is.list(clustering)) { stop("object supplied to clustering= is not a list, see Arguments in ?find_optimal") }
    if (!all(unlist(lapply(clustering, is.atomic)))) { stop("some components list supplied to clustering= are not atomic vectors, see Arguments in ?find_optimal. Try: unlist(lapply(clustering, class))") }
    if (!cutree & !zero_range(unlist(lapply(clustering, length)))) { stop("Number of sample labels do not match in all components of the list supplied to clustering=, see Arguments in ?find_optimal") }
    if (!cutree & !length(clustering[[1]] == nrow(data))) { stop("Number of sample labels in list components supplied to clustering= does not match the number of rows of object supplied to data=. See Arguments in ?find_optimal") }
    message("they will be coerced to factors.")
  }

  # make list of clustering solutions from cutree-able object
  if (cutree) {
    cutree_to_list <- function(x, clustering) {cutree(tree = clustering, k = x)}
    cluster_list <- lapply(X = as.list(cutreeLevels), FUN = cutree_to_list, clustering = clustering)
  }

  # make list of clustering solutions from user supplied object
  if (!cutree) { cluster_list <- lapply(X = clustering, FUN = as.character) }

  # get nclusters
  nclusters <- unlist(lapply(X = cluster_list, FUN = function(x) { length(unique(x)) } ))

  # fit models to calculate sum-of-aic
  if (family == "gaussian") {
    aic_sums <- data.frame(sum_aic = gaussian_loop(cluster_list, data, nclusters),
                           nclusters = nclusters)
  }

  if (family == "negative.binomial") {
    aic_sums <- data.frame(sum_aic = negbin_loop(cluster_list, data),
                           nclusters = nclusters)
  }

  if (family == "poisson") {
    aic_sums <- data.frame(sum_aic = poisson_loop(cluster_list, data),
                           nclusters = nclusters)
  }

  if (family == "binomial") {
    aic_sums <- data.frame(sum_aic = binomial_loop(cluster_list, data, K=K),
                           nclusters = nclusters)
  }

  if (family == "ordinal") {
    aic_sums <- data.frame(sum_aic = ordinal_loop(cluster_list, data),
                           nclusters = nclusters)
  }

  # attributes/class for aic_sums
  attr(aic_sums, "family") <- family
  if (family == "binomial") {attr(aic_sums, "K") <- K}
  attr(aic_sums, "cutree") <- cutree
  attr(aic_sums, "cutreeLevels") <- cutreeLevels
  class(aic_sums) <- c("aicsums","data.frame")

  # return data frame ready for plotting
  aic_sums
}

